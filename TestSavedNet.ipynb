{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytreebank\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = pytreebank.load_sst(\"stanfordSentimentTreebank/trees\")\n",
    "\n",
    "dictFile = open(\"stanfordSentimentTreebank/dictionary.txt\")\n",
    "lines = dictFile.readlines()\n",
    "exp = r'^(\\S+)\\|\\d+$'\n",
    "unfilterdWords = map(lambda line: re.findall(exp, line), lines)\n",
    "words = list(map(lambda x: x.replace('\\\\', ''),\n",
    "            map(lambda x: x[0],\n",
    "            filter(lambda x: len(x) > 0, \n",
    "            unfilterdWords))))\n",
    "words.append('8 1/2')\n",
    "words.append('2 1/2')\n",
    "words.append('9 1/2')\n",
    "\n",
    "dictionary = dict((word, number) for number, word in enumerate(words))\n",
    "\n",
    "def oneHotEncoding(word):\n",
    "    ##if word.find('/') != -1:\n",
    "    ##    tmp = word.split('/')\n",
    "    ##    word = tmp[0] + '\\/' + tmp[1]\n",
    "    vector = torch.zeros(1, len(dictionary)).cuda()\n",
    "    vector[0][dictionary[word]] = 1\n",
    "    return vector\n",
    "\n",
    "def getLabels(tree):\n",
    "    labels = []\n",
    "    if len(tree.children) == 2:\n",
    "        labels.extend(getLabels(tree.children[0]))\n",
    "        labels.extend(getLabels(tree.children[1]))\n",
    "        labels.extend([tree.label])\n",
    "        return labels\n",
    "    else:\n",
    "        return [tree.label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNTN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocabularySize, classes = 5, d = 25):\n",
    "        super(RNTN, self).__init__()\n",
    "        self.d = d\n",
    "        self.L = nn.Linear(vocabularySize, d, bias=False)\n",
    "        self.W = nn.Linear(d * 2, d)\n",
    "        self.Ws = nn.Linear(d,  classes)\n",
    "        self.register_parameter('V', nn.Parameter(torch.rand(2 * d, 2 * d, d).cuda()))\n",
    "        self.lSoftmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def tensorProduct(self, phrase):    \n",
    "        result = torch.empty(1, self.d).cuda()\n",
    "        for i in range(self.d):\n",
    "            result[0][i] = torch.mm(phrase, torch.mm(self.V[:,:,i], torch.t(phrase)))\n",
    "        return result\n",
    "    \n",
    "    def embed(self, inpt):\n",
    "        return self.L(inpt)\n",
    "    \n",
    "    def getSentiment(self, inpt):\n",
    "        return self.lSoftmax(self.Ws(inpt))\n",
    "    \n",
    "    def forward(self, root):\n",
    "        \n",
    "        self.outputs = []\n",
    "        self.phraseStack = []\n",
    "        visited = []\n",
    "        stack = [root]\n",
    "        \n",
    "        while len(stack) > 0:\n",
    "            \n",
    "            node = stack[-1]\n",
    "            if len(node.children) == 2:\n",
    "                ## Calculate phrase vector of the children\n",
    "                if node not in visited:\n",
    "                    stack.append(node.children[1])\n",
    "                    stack.append(node.children[0])\n",
    "                    visited.append(node)\n",
    "                else:\n",
    "                    ## Calculate phrase vector of the node\n",
    "                    inpt2 = self.phraseStack.pop()\n",
    "                    inpt1 = self.phraseStack.pop()\n",
    "                    phraseVec = torch.cat([inpt1, inpt2], dim=1)\n",
    "                    phraseVec = torch.tanh(self.tensorProduct(phraseVec) + self.W(phraseVec))\n",
    "                    self.phraseStack.append(phraseVec)\n",
    "                    \n",
    "                    ## Save the outputs of the backpropagation\n",
    "                    self.outputs = torch.cat([self.outputs, self.getSentiment(phraseVec)], dim=0)\n",
    "                    \n",
    "                    stack.pop()\n",
    "            else:\n",
    "                phraseVec = self.embed(oneHotEncoding(node.to_lines()[0]))\n",
    "                self.phraseStack.append(phraseVec)\n",
    "                if len(self.outputs) == 0:\n",
    "                    self.outputs = self.getSentiment(phraseVec)\n",
    "                else:\n",
    "                    self.outputs = torch.cat([self.outputs, self.getSentiment(phraseVec)], dim=0)\n",
    "                stack.pop()\n",
    "        return self.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine grained accuracy on the test set: 35.88235294117647%\n"
     ]
    }
   ],
   "source": [
    "testNet = RNTN(len(dictionary))\n",
    "testNet.cuda()\n",
    "testNet.load_state_dict(torch.load('./net.pth'))\n",
    "testNet.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = len(bank['test'])\n",
    "    for sentence in bank['test']:\n",
    "        outputs = testNet(sentence).cuda()\n",
    "        targets = torch.tensor(getLabels(sentence)).cuda()\n",
    "\n",
    "        if torch.argmax(outputs[-1]) == targets[-1]:\n",
    "            correct += 1\n",
    "\n",
    "    print(f'Fine grained accuracy on the test set: {correct/total * 100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
